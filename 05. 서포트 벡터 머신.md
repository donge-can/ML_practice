### 05. 서포트 벡터 머신

>  *2019-1학기 머신러닝 수업을 통해 배운 것을 정리
>
>  교재: R을 활용한 머신러닝 / 저자: Brett Lantz 

<br>

### 1. 서포트 벡터 머신의 이해

> 초평면이라고 하는 경계를 사용해 데이터를 유사한 클래스 값들의 그룹으로 분할

- 서포트 벡터 머신은 다차원 공간에 표시되는 점들 사이에 경계를 만드는 표면으로 상상해 볼 수 있다

- SVM의 목표는 **공간을 나눠** 양쪽에 매우 균질적인 분할을 생성하는 초평면이라고 하는 **평평한 경계를 생성**하는 것이다.



​											[![img](https://blogfiles.pstatic.net/MjAxOTA3MDhfMjA0/MDAxNTYyNTUzOTgzMDA1.Z4s9R_K9IDzlGF39jTu0faBmvOnhloX4BAZ-ZWgHRpwg.OtP5xgK1BwYBSNUiAkijLAK0TpX97ni6jMIwLVMFwQ0g.PNG.bosongmoon/i mage.png?type=w1)](https://blog.naver.com/PostView.nhn?blogId=bosongmoon&logNo=221581160865&parentCategoryNo=&categoryNo=69&viewDate=&isShowPopularPosts=false&from=postList#)



- 이차원에서 SVM 알고리즘의 작업은 두 클래스를 나누는 직선을 찾는 것이다(Separating Hyperplane). 아래 그림에서 보이는 것처럼 원과 사각형 그룹 사이에는 선택할 수 있는 분할 직선이 하나 이상 존재한다. 그럼 여러개의 후보 중 하나를 어떻게 선택해야 하는가?

  ​																![image-20200110190443761](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20200110190443761.png)

  - 두 클래스 사이를 가장 멀리 분리하는 `최대 마진 초평면을 찾는 것(Margin)`과 관련돼 있다. 아래 그림에서 원과 정사각형을 분리하고 있는 세개의 직선 모두 데이터 포인트를 정확하게 분류하지만, 가장 멀리 분리하게 만드는 직선이 미래 데이터에 대해 가장 일반화를 잘할 것이다.

    ​															![image-20200110190618206](C:\Users\user\AppData\Roaming\Typora\typora-user-images\image-20200110190618206.png)

    

- 최대 마진은 임의의 잡음이 있더라도 점이 경계의 올바른 쪽에 남게 될 가능성을 높일 것이다. `서포트 벡터`(Support Vectors)는 각 클래스에서 `최대 마진 초평면에 가장 가까운 점`들이다. 서포트 벡터만을 사용해서 최대 마진 초평면 MMH를 정의할 수 있다. 이것이 SVM의 주요 특징이다. 특징의 개수가 엄청나게 많더라도 서포트 벡터는 분류 모델을 저장하기 위한 아주 간결한 방법을 제공한다.

<br>

- 예시
  - 암이나 다른 유전병 식별을 위한 생체 정보학 분야의 미세 배열 유전자 발현 데이터의 분류
  - 문서에서 사용되는 언어의 식별 또는 주제별 문서 분류와 같은 텍스트 범주화
  - 연소기관의 고장, 보안 결함 또는 지진과 같은, 드물지만 중요한 사건의 탐지

<br>

### 2. 장점과 단점

- 장점
  - 분류 또는 수치 예측 문제에 사용될 수 있다
  - 잡음에 거의 영향을 받지 않으며, 과적합도 쉽게 일어나지 않느다
  - 신경망을 사용하는 것보다 쉬운데, 특히 잘 지원되는 SVM 알고리즘들이 있기 때문이다

<br>

- 단점

  - 최고의 모델을 찾기 위해 커널과 모델 파라미터의 다양한 조합을 테스트해야 한다

  - 훈련이 느릴 수 있으며, 특히 입력 데이터 셋이 아주 많은 특징이나 예시를 갖는 경우 느리다

  - 불가능하진 않지만, 해석하기 어려운 복잡한 블랙박스 모델이 만들어진다

<br>

### 3. 선형 분리 불가능

- 데이터를 이차원 공간에 표현했을 때, 선형적으로 분리 가능한 경우가 있고, 분리 할 수 없는 경우가 있다.

- 선형적으로 분리 가능한 경우에는, 해당 공식에 의해 최대 마진 평면을 찾으면 된다.

- 선형적으로 분리할 수 없는 경우에는, 비선형 공간을 위한 `커널kernel`을 사용해서, 분리할 수 있는 수준으로 `차원`을 올려줘야 한다.



[![img](https://postfiles.pstatic.net/MjAxOTA3MDhfNjcg/MDAxNTYyNTYyNTI3Mzkx.mI59unkzdOejzOUDVxC9PoV1MYP_jo3XKKjCjAIux4Eg.iX9ApcAYkafMSSm4soWOlsCp3SXnF1MLlr9AQR4mu38g.PNG.bosongmoon/image.png?type=w773)](https://blog.naver.com/PostView.nhn?blogId=bosongmoon&logNo=221581160865&parentCategoryNo=&categoryNo=69&viewDate=&isShowPopularPosts=false&from=postList#)

​																		**선형적으로 분리할 수 없는 경우**

<br>





​								[![img](https://postfiles.pstatic.net/MjAxOTA3MDhfMTI1/MDAxNTYyNTYyNTg2MDQ4.3cx4A0IUbWJuzuEtGxiduqqzyjwkr0462W6uqgZShJEg.R6gnkUFalEkc7y9F2rx5BAaR2FuAP29V4ZOTfAGBkeog.PNG.bosongmoon/image.png?type=w773)](https://blog.naver.com/PostView.nhn?blogId=bosongmoon&logNo=221581160865&parentCategoryNo=&categoryNo=69&viewDate=&isShowPopularPosts=false&from=postList#)

​																	**고차원으로 매핑했을 때**

<br>

- `커널 트릭 kernel trick`을 사용해서, 분리할 수 있는 고차원 공간으로 매핑해야 한다. 그러면, 비선형 관계가 선형적인 관계로 나타날 수 있다.

  ​						[![img](https://postfiles.pstatic.net/MjAxOTA3MDhfNTYg/MDAxNTYyNTYzMTAxNTI3.Cl5O5oXzbqRRfcL4Mmm5rc7LsWSAAtW_GoifRZU6dusg.VJUn0UPGMb6RES29DDttPlfUfZLkSS0mezJBbEkXKOgg.PNG.bosongmoon/image.png?type=w773)](https://blog.naver.com/PostView.nhn?blogId=bosongmoon&logNo=221581160865&parentCategoryNo=&categoryNo=69&viewDate=&isShowPopularPosts=false&from=postList#)

  
  - 이차원으로 되어 있는 그래프에서 `커널 트릭`(고차원으로 보내주는 함수)을 사용해서, 선형으로 분리할 수 있는 공간을 만들어주었다.